<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chương 1 Boosting và cây quyết định. | bookdown-demo.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chương 1 Boosting và cây quyết định. | bookdown-demo.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chương 1 Boosting và cây quyết định. | bookdown-demo.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="reference.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">KHDL KT&KD</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="boosting-và-cây-quyết-định..html"><a href="boosting-và-cây-quyết-định..html"><i class="fa fa-check"></i><b>1</b> Boosting và cây quyết định.</a>
<ul>
<li class="chapter" data-level="1.1" data-path="boosting-và-cây-quyết-định..html"><a href="boosting-và-cây-quyết-định..html#những-cơ-sở-của-kỹ-thuật-boosting"><i class="fa fa-check"></i><b>1.1</b> Những cơ sở của kỹ thuật boosting</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>2</b> REFERENCE</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="boosting-và-cây-quyết-định." class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chương 1</span> Boosting và cây quyết định.<a href="boosting-và-cây-quyết-định..html#boosting-và-cây-quyết-định." class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Trong một vài cuốn sách, boosting được dịch sang tiếng Việt là học tăng cường, tuy nhiên trong cuốn sách này, chúng tôi giữ nguyên khái niệm này bởi vì chúng tôi không nghĩ rằng học tăng cường giải nghĩa được chính xác ý tưởng của Boosting. Tính đến thời điểm chúng tôi đang viết cuốn sách này, có thể khẳng định rằng boosting là một trong những ý tưởng mạnh mẽ nhất trong lĩnh vực học máy. Ban đầu boosting được áp dụng cho các bài toán phân loại, nhưng bạn đọc sẽ thấy rằng có thể dễ dàng áp dụng boosting cho các bài toán hổi quy để cho kết quả hơn cả mong đợi. Ý tưởng chung của boosting là kết hợp kết quả đầu ra của nhiều hàm phân loại, hoặc hàm hồi quy “yếu”, để tạo ra một hàm phân loại hoặc hồi quy “mạnh”. Cùng là kết hợp nhiều hàm phân loại hay hổi quy, tuy nhiên boosting khác bagging hay random forest ở chỗ các hàm phân loại hoặc hồi quy được tạo ra theo thứ tự nhất định mà trong đó hàm phân loại hay hồi quy được tạo ra ở bước thứ <span class="math inline">\(m\)</span> sẽ phụ thuộc vào kết quả của hàm đó tại các bước thứ <span class="math inline">\(1, 2, \cdots, (m-1)\)</span>. Trong bagging hay random forest, cách xây dựng hàm phân loại hay hổi quy ở lần thứ <span class="math inline">\(m\)</span> hoàn toàn không phụ thuộc vào kết quả của các bước trước đó.</p>
<p>Khái niệm boosting lần đầu tiên được nhắc đến trong nghiên cứu của Freund và Schapire (1997). Chúng tôi gọi thuật toán được giới thiệu trong nghiên cứu của Freund và Schapire là “AdaBoost.M1” để phân biệt với thuật toán AdaBoost thông dụng hiện nay. Trong bài toán phân loại, biến mục tiêu chỉ nhận hai giá trị <span class="math inline">\(Y \in \{-1,1\}\)</span>. Hàm phân loại được ký hiệu là <span class="math inline">\(f^C\)</span> và với véc-tơ biến độc lập <span class="math inline">\(\textbf{x}_i\)</span> chúng ta có <span class="math inline">\(f^C(\textbf{x}_i) \in \{-1,1\}\)</span>. Sai số của hàm phân loại <span class="math inline">\(f^C\)</span> trên dữ liệu <span class="math inline">\((\textbf{x},y)\)</span> được tính như sau
<span class="math display">\[\begin{align}
err(\textbf{x},y) = \cfrac{1}{n} \ \sum\limits_{i=1}^n \mathbb{I}\left(f^C(\textbf{x}_i) \neq y_i \right)
\end{align}\]</span></p>
<p>Môt hàm phân loại “yếu” <span class="math inline">\(f^C\)</span> là một hàm phân loại có khả năng dự báo chỉ tốt hơn một chút so với việc phân loại một cách ngẫu nhiên. Ý tưởng của boosting là áp dụng tuần tự các hàm phân loại yếu trên các phiên bản dữ liệu được liên tục cập nhật dựa trên kết quả của các hàm phân loại trước đó. Hàm phân loại cuối cùng thu được bằng cách kết hợp có trọng số tất cả các hàm phân loại:
<span class="math display">\[\begin{align}
f(x) =  sign\left( \sum\limits_{m=1}^M \alpha_m \cdot f_m^C(x)  \right)
\end{align}\]</span>
trong đó các hệ số <span class="math inline">\(\alpha_1, \alpha_2, \cdots, \alpha_M\)</span> được tính toán khả năng phân loại của các hàm <span class="math inline">\(f^C_1, f^C_2, \cdots, f^C_M\)</span>.</p>
<p>Quá trình cập nhật và thay đổi dữ liệu ở mỗi bước của boosting được thực hiện thông qua thay đổi véc-tơ trọng số <span class="math inline">\(w^{(m)}_1, w^{(m)}_2, \cdots ,w^{(m)}_n\)</span> cho từng quan sát trong dữ liệu xây dựng mô hình <span class="math inline">\((\textbf{x}_i,y_i)\)</span>, với <span class="math inline">\(i = 1, 2, \cdots ,n\)</span>, và <span class="math inline">\(m = 1, 2, \cdots, M\)</span>.</p>
<p>Ban đầu tất cả các trọng số được cho bằng nhau tại bước thứ nhất <span class="math inline">\(w^{(1)}_i = \cfrac{1}{n}\)</span> với mọi <span class="math inline">\(i\)</span>. Trong bước đầu tiên, hàm phân loại được xây dựng trên dữ liệu ban đầu theo cách thông thường. Đối với những lần xây dựng hàm phân loại tiếp theo <span class="math inline">\(m = 2, 3, \cdots ,M\)</span>, trọng số <span class="math inline">\(w^{(m)}_i\)</span> của quan sát thứ <span class="math inline">\(i\)</span> thay đổi và hàm phân loại được áp dụng lại cho dữ liệu với trọng số vừa cập nhật. Tại bước thứ <span class="math inline">\(m\)</span>, nếu quan sát thứ <span class="math inline">\(i\)</span> bị phân loại sai bởi hàm phân loại ở bước ngay liền trước đó, <span class="math inline">\(f^C_{m-1}(x_i)\)</span>, trọng số <span class="math inline">\(w^{(m)}_i\)</span> sẽ được tăng lên. Ngược lại, nếu quan sát thứ <span class="math inline">\(i\)</span> được phân loại đúng ở bước <span class="math inline">\((m-1)\)</span>, trọng số <span class="math inline">\(w^m_i\)</span> sẽ được giảm đi. Khi quá trình kể trên diễn ra lặp đi lặp lại, những quan sát khó phân loại chính xác sẽ nhận càng có tỷ trọng cao trong những bước phân loại tiếp theo. Những hàm phân loại xây dựng cho những bước sau sẽ tập trung vào phân loại những quan sát mà những hàm phân loại ở các bước trước đã bỏ sót.</p>
<p>Thuật toán AdaBoost.M1 được mô tả trong nghiên cứu của Freund và Schapire (1997) được phát biểu như sau:</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Cho <span class="math inline">\(w^{(1)}_i = \cfrac{1}{n}\)</span> với mọi <span class="math inline">\(i = 1, 2, \cdots, n\)</span> với <span class="math inline">\(n\)</span> là số dòng của dữ liệu ban đầu.</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Tại bước thứ <span class="math inline">\(m\)</span>, với <span class="math inline">\(m = 1, 2, \cdots, M\)</span>,</li>
</ol>
<ul>
<li><p>2.(a) Xây dựng hàm phân loại <span class="math inline">\(f^C_m\)</span> trên dữ liệu ban đầu với véc-tơ trọng số tương ứng với dòng <span class="math inline">\(i\)</span> là <span class="math inline">\(w^{(m)}_i\)</span>.</p></li>
<li><p>2.(b) Tính toán sai số của hàm phân loại <span class="math inline">\(f^C_m\)</span></p></li>
</ul>
<p><span class="math display">\[\begin{align}
err_m = \sum\limits_{m=1}^M  w^{(m)}_i \cdot \mathbb{I} \left(f_m^C(\textbf{x}_i) \neq y_i \right)
\end{align}\]</span></p>
<ul>
<li>2.(c) Tính hệ số của hàm phân loại thứ <span class="math inline">\(m\)</span> dựa trên sai số</li>
</ul>
<p><span class="math display">\[\begin{align}
\alpha_m = \log\left( \cfrac{1 - err_m}{err_m} \right)
\end{align}\]</span></p>
<ul>
<li>2.(d). Cập nhật trọng số cho bước tiếp theo</li>
</ul>
<p><span class="math display">\[\begin{align}
w^{(m+1)}_i = w^{(m)}_i \cdot \exp\left[ \alpha_m \cdot \mathbb{I} \left(f_m^C(\textbf{x}_i) \neq y_i \right) \right]
\end{align}\]</span></p>
<ul>
<li>2.(e). Chuẩn hóa lại trọng số để tổng các trọng số bằng 1.</li>
</ul>
<p><span class="math display">\[\begin{align}
w^{(m+1)}_i = \cfrac{w^{(m+1)}_i}{\sum\limits_{i=1}^n  w^{(m+1)}_i}
\end{align}\]</span></p></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Kết thúc lần lặp thứ <span class="math inline">\(M\)</span>, trả lại kết quả hàm phân loại cuối cùng:
<span class="math display">\[\begin{align}
f^C(x) =  sign\left( \sum\limits_{m=1}^M \alpha_m \cdot f_m^C(x)  \right)
\end{align}\]</span></li>
</ol></li>
</ul>
<p>Chúng tôi khuyên bạn đọc hãy hiểu ý tưởng của các bước kể trên thay vì cố gắng hiểu cặn kẽ công thức toán học. Các bước của thuật toán AdaBoost.M1 được trình bày ở trên khá rõ ràng, ngoại trừ bước 2.(a) là “Xây dựng hàm phân loại <span class="math inline">\(f^C_m\)</span> trên dữ liệu ban đầu với véc-tơ trọng số tương ứng với dòng <span class="math inline">\(i\)</span> là <span class="math inline">\(w^{(m)}_i\)</span>”. Quá trình xây dựng một hàm phân loại luôn luôn bao gồm hai bước: bước thứ nhất là lựa chọn kiểu mô hình và bước thứ hai là ước lượng tham số của mô hình với mục tiêu tối thiểu hóa một hàm tổn thất. Thuật toán AdaBoost.M1 ở trên có thể được áp dụng với mọi hàm phân loại (cây quyết định, hồi quy logistic, …) nhưng hàm tổn thất được lựa chọn phải là hàm tổn thất kiểu mũ. Trong các phần tiếp theo của cuốn sách bạn đọc sẽ được giải thích rằng công thức tính toán các trọng số <span class="math inline">\(w^{(m)}_i\)</span> ở bước 2.(d) là kết quả của việc lựa chọn hàm tổn thất, trong khi hàm phân loại có thể là bất cứ dạng hàm nào.</p>
<p>Thuật toán AdaBoost.M1 được Friedman (2000) gọi là thuật toán AdaBoost phân loại vì các hàm <span class="math inline">\(f^C_m\)</span> được xây dựng ở bước thứ <span class="math inline">\(m\)</span> luôn là các dạng hàm phân loại. Nghiên cứu của Friedman (2000) điều chỉnh AdaBoost.M1 để phù hợp hơn cho cả bài toán phân loại và bài toán hồi quy. Hàm phân loại trong nghiên cứu của Friedman luôn luôn có dạng là một cây quyết định có 1 node duy nhất, còn được gọi là một “stump”. Một stump chỉ là một hàm phân loại yếu, nhưng bằng cách kết hợp các stump như ý tưởng của AdaBoost.M1, khả năng dự đoán của hàm phân loại cuối cùng là đáng kinh ngạc. Thuật toán được giới thiệu trong nghiên cứu của Friedman (2000) chính là thuật toán AdaBoost được áp dụng rộng rãi hiện nay.</p>
<p>Trong chương này chúng tôi sẽ giới thiệu đến bạn đọc những nội dung như sau:</p>
<!-- - Phần thứ nhất: Chúng tôi chứng minh rằng AdaBoost phù hợp với mô hình cộng tính trong trình học cơ sở, tối ưu hóa hàm mất mũ mới. Hàm mất này rất giống với khả năng ghi nhật ký nhị thức (âm) (Phần 10.2– 10.4). • Bộ giảm thiểu dân số của hàm mất mũ được biểu diễn bằng log-odds của các xác suất của lớp (Phần 10.5). • Chúng tôi mô tả các hàm mất mát cho hồi quy và phân loại mạnh hơn sai số bình phương hoặc mất mát theo cấp số nhân (Phần 10.6). • Người ta lập luận rằng cây quyết định là một trình học cơ sở lý tưởng cho các ứng dụng khai thác dữ liệu tăng cường (Phần 10.7 và 10.9). • Chúng tôi phát triển một lớp mô hình tăng cường độ dốc (GBM), để tăng cường cây có bất kỳ chức năng mất nào (Phần 10.10). • Tầm quan trọng của “học chậm” được nhấn mạnh và được thực hiện bằng cách thu gọn từng thuật ngữ mới đưa vào mô hình (Phần 10.12), cũng như ngẫu nhiên hóa (Phần 10.12.2). • Mô tả các công cụ giải thích mô hình phù hợp (Phần 10.13) -->
<div id="những-cơ-sở-của-kỹ-thuật-boosting" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Những cơ sở của kỹ thuật boosting<a href="boosting-và-cây-quyết-định..html#những-cơ-sở-của-kỹ-thuật-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Xây dựng mô hình dựa trên kỹ thuật boosting về cơ bản là kết hợp tuyến tính một tập hợp các hàm cơ bản nhằm cải thiện khả năng giải thích hoặc dự đoán. Một cách tổng quát, hàm <span class="math inline">\(f\)</span> thu được từ kỹ thuật boosting có thể viết dưới dạng tổng của <span class="math inline">\(M\)</span> hàm phân loại hoặc hồi quy như sau:
<span class="math display" id="eq:boosting1">\[\begin{align}
f(\textbf{x}) = \sum\limits_{m=1}^M \ \lambda_m \cdot b(\textbf{x},\theta_m)
\tag{1.1}
\end{align}\]</span>
trong đó <span class="math inline">\(\lambda_m\)</span> là hệ số tuyến tính, <span class="math inline">\(b(\textbf{x},\theta_m)\)</span> là một hàm phân loại hoặc hồi quy cơ bản có tham số là <span class="math inline">\(\theta_m\)</span>. Dạng tham số của hàm <span class="math inline">\(b\)</span> thường được xác định trước khi xây dựng hàm <span class="math inline">\(f\)</span> trong khi các tham số <span class="math inline">\(\lambda_m\)</span> và <span class="math inline">\(\theta_m\)</span> được ước lượng tại mỗi bước nhằm tối thiểu hóa hàm tổn thất. Quá trình ước lượng tham số của mô hình <a href="boosting-và-cây-quyết-định..html#eq:boosting1">(1.1)</a> được thực hiện thông qua các bước như sau:</p>
<ul>
<li><p>Bước 1: Lựa chọn hàm tổn thất <span class="math inline">\(\sum\limits_{i=1}^n L(y_i, \hat{y}_i)\)</span>, dạng hàm cơ bản <span class="math inline">\(b(\textbf{x},\theta)\)</span>, và cho <span class="math inline">\(f_0(\textbf{x}) = 0\)</span>.</p></li>
<li><p>Bước 2: với mỗi <span class="math inline">\(m = 1, 2, \cdots, M\)</span>, tìm tham số (<span class="math inline">\(\lambda_m\)</span>,<span class="math inline">\(\theta_m\)</span>) như sau
<span class="math display">\[\begin{align}
(\lambda_m,\theta_m) = \underset{\lambda,\theta}{\operatorname{argmax}} \sum\limits_{i=1}^n L\left( y_i, f_{m-1}(x_i) + \lambda \cdot b(\textbf{x}_i,\theta) \right)
\end{align}\]</span></p></li>
<li><p>Bước 3: cho <span class="math inline">\(f_m(\textbf{x}) = f_{m-1}(\textbf{x}) + \lambda_m \cdot b(\textbf{x}_i,\theta_m)\)</span>.</p></li>
</ul>
<p>Tại mỗi bước <span class="math inline">\(m = 1, 2, \cdots, M\)</span>, chúng ta cần phải tìm các tham số (<span class="math inline">\(\lambda_m\)</span>,<span class="math inline">\(\theta_m\)</span>) để tối thiểu hóa một hàm tổn thất. Khi giải bài toán tối ưu, lời giải chính xác luôn được ưu tiên trước, nếu không thể giải bằng lời giải chính xác mới cần sử dụng phương pháp số. Việc tồn tại hay không tồn tại lời giải chính xác cho mỗi bước <span class="math inline">\(m\)</span> phụ thuộc vào lựa chọn hàm tổn thất <span class="math inline">\(L\)</span> và hàm cơ bản <span class="math inline">\(b\)</span>. Hàm cơ bản <span class="math inline">\(b\)</span> thường được lựa chọn ở mức độ đơn giản nhất, chẳng hạn như 1 cây quyết định với 1 node. Hàm tổn thất có thể là hàm tổn thất kiểu mũ, hàm tổn thất kiểu trung bình sai số, hàm hợp lý,…</p>
<ul>
<li><p>Ví dụ 1: trong bài toán hồi quy, khi hàm tổn thất là hàm tổng sai số bình phương,
<span class="math display">\[\begin{align}
L(y_i, \hat{y}_i) = \cfrac{1}{2} \sum\limits_{i=1}^n (y_i - \hat{y}_i)^2
\end{align}\]</span>
tham số <span class="math inline">\((\lambda_m,\theta_m)\)</span> là lời giải của bài toán tối ưu sau
<span class="math display">\[\begin{align}
(\lambda_m,\theta_m) &amp; = \underset{\lambda,\theta}{\operatorname{argmin}} \cfrac{1}{2} \sum\limits_{i=1}^n \left(y_i - f_{m-1}(x_i) - \lambda \cdot b(\textbf{x}_i,\theta) \right)^2 \\
&amp; = \underset{\lambda,\theta}{\operatorname{argmin}} \cfrac{1}{2} \sum\limits_{i=1}^n \left(\epsilon_{i,m-1}  - \lambda \cdot b(\textbf{x}_i,\theta) \right)^2
\end{align}\]</span>
trong đó <span class="math inline">\(\epsilon_{i,m-1}\)</span> là sai số của thuật toán Boosting sau bước thứ <span class="math inline">\((m-1)\)</span>. Bạn đọc có thể thấy rằng nếu chúng ta chọn hàm tổn thất là tổng sai số bình phương, tại bước thứ <span class="math inline">\(m\)</span> của quá trình boosting, chúng ta sẽ cần tìm các hệ số <span class="math inline">\((\lambda_m,\theta_m)\)</span> sao cho tổng sai số giữa <span class="math inline">\(\lambda_m \cdot b(\textbf{x}_i,\theta_m)\)</span> và sai số tại bước thứ <span class="math inline">\((m-1)\)</span>, <span class="math inline">\(\epsilon_{i,m-1}\)</span> là nhỏ nhất.</p></li>
<li><p>Ví dụ 2: trong bài toán phân loại mà biến mục tiêu <span class="math inline">\(y\)</span> chỉ nhận hai giá trị là -1 hoặc 1, Freund và Schapire (1997) lựa chọn hàm tổn thất kiểu mũ
<span class="math display">\[\begin{align}
L(y_i, \hat{y}_i) = \sum\limits_{i=1}^n exp(- y_i \cdot \hat{y_i})
\end{align}\]</span>
tham số <span class="math inline">\((\lambda_m,\theta_m)\)</span> là lời giải của bài toán tối ưu sau
<span class="math display">\[\begin{align}
(\lambda_m,\theta_m) &amp; = \underset{\lambda,\theta}{\operatorname{argmin}} \sum\limits_{i=1}^n \exp\left[- y_i  \cdot \left(f_{m-1}(x_i) + \lambda \cdot b(\textbf{x}_i,\theta) \right) \right] \\
&amp; = \underset{\lambda,\theta}{\operatorname{argmin}} \sum\limits_{i=1}^n \exp\left[ - y_i  \cdot f_{m-1}(x_i)\right]  \cdot \exp\left[- y_i \cdot \lambda \cdot b(\textbf{x}_i,\theta)  \right] \\
&amp; = \underset{\lambda,\theta}{\operatorname{argmin}} \sum\limits_{i=1}^n w_i^{(m)}  \cdot \exp\left[- \lambda \cdot y_i \cdot b(\textbf{x}_i,\theta)  \right]
\end{align}\]</span>
với <span class="math inline">\(w_i^{(m)} = \exp\left[ - y_i \cdot f_{m-1}(x_i)\right]\)</span>. Bạn đọc có thể thấy rằng <span class="math inline">\(w_i^{(m)}\)</span> không phụ thuộc vào <span class="math inline">\(\lambda\)</span> hay <span class="math inline">\(\theta\)</span> nên có thể coi như trọng số tương ứng với dữ liệu thứ <span class="math inline">\(i\)</span>.</p></li>
</ul>
<p>Từ kết quả của ví dụ 2, chúng ta đã có thể giải thích các bước trong thuật toán AdaBoost.M1. Với mọi <span class="math inline">\(\lambda &gt; 0\)</span> và với một lựa chọn của hàm <span class="math inline">\(b\)</span>, tham số <span class="math inline">\(\theta_m\)</span> là giá trị tối thiểu hóa hàm tổn thất
<span class="math display" id="eq:boosting2">\[\begin{align}
(\theta_m) &amp; = \underset{\theta}{\operatorname{argmin}} \sum\limits_{i=1}^n w_i^{(m)}  \cdot \exp\left[- \lambda \cdot y_i \cdot b(\textbf{x}_i,\theta)  \right] \\
\tag{1.2}
\end{align}\]</span>
Biến đổi công thức phía bên phải của phương trình <a href="boosting-và-cây-quyết-định..html#eq:boosting2">(1.2)</a> chúng ta có
<span class="math display" id="eq:boosting3">\[\begin{align}
\sum\limits_{i=1}^n w_i^{(m)}  \cdot \exp\left[- \lambda \cdot y_i \cdot b(\textbf{x}_i,\theta)  \right] &amp; = \sum\limits_{i=1}^n w_i^{(m)}  \cdot \left[ e^{-\lambda} \cdot \mathbb{I}(y_i = b(\textbf{x}_i,\theta)) + e^{\lambda} \cdot \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta))  \right]\\
&amp; = \sum\limits_{i=1}^n w_i^{(m)}  \cdot e^{-\lambda} +  \sum\limits_{i=1}^n w_i^{(m)}  \cdot \left[ e^{\lambda} - e^{-\lambda} \right] \cdot \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta)) \\
&amp; = e^{-\lambda} \cdot \sum\limits_{i=1}^n w_i^{(m)}  + \left[ e^{\lambda} - e^{-\lambda} \right] \cdot  \sum\limits_{i=1}^n w_i^{(m)}  \cdot  \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta))
\tag{1.3}
\end{align}\]</span></p>
<p>Do <span class="math inline">\(e^{\lambda} - e^{-\lambda} &gt; 0\)</span> và các <span class="math inline">\(w_i^{(m)}\)</span> không phụ thuộc vào <span class="math inline">\(\theta\)</span> nên ta có giá trị <span class="math inline">\(\theta_m\)</span> tối thiểu hóa hàm tổn thất trong phương trình <a href="boosting-và-cây-quyết-định..html#eq:boosting2">(1.2)</a> cũng là giá trị <span class="math inline">\(\theta_m\)</span> tối thiểu hóa sai số dự đoán
<span class="math display" id="eq:boosting4">\[\begin{align}
(\theta_m) &amp; = \underset{\theta}{\operatorname{argmin}} \sum\limits_{i=1}^n w_i^{(m)}  \cdot  \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta))
\tag{1.4}
\end{align}\]</span></p>
<p>Với mỗi <span class="math inline">\(\theta_m\)</span> là lời giải của <a href="boosting-và-cây-quyết-định..html#eq:boosting4">(1.4)</a>, chúng ta có giá trị <span class="math inline">\(\lambda_m\)</span> để tối thiểu hóa giá trị hàm tổn thất trong phương trình <a href="boosting-và-cây-quyết-định..html#eq:boosting2">(1.2)</a> là lời giải của phương trình
<span class="math display">\[\begin{align}
\sum\limits_{i=1}^n w_i^{(m)}  \cdot \cfrac{\partial \exp\left[- \lambda \cdot y_i \cdot b(\textbf{x}_i,\theta_m)  \right]}{\partial \lambda} = 0 \\
\end{align}\]</span></p>
<p>Lấy đạo hàm của vế phải của phương trình <a href="boosting-và-cây-quyết-định..html#eq:boosting4">(1.4)</a> theo <span class="math inline">\(\lambda\)</span> chúng ta có:
<span class="math display">\[\begin{align}
&amp; - e^{-\lambda_m} \cdot \sum\limits_{i=1}^n w_i^{(m)}  + \left[ e^{\lambda_m} + e^{-\lambda_m} \right] \cdot  \sum\limits_{i=1}^n w_i^{(m)}  \cdot  \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta_m)) = 0 \\
&amp; \rightarrow \lambda_m = \cfrac{1}{2} \cdot \log\left(\cfrac{1}{err_m} - 1 \right)
\end{align}\]</span>
với <span class="math inline">\(err_m\)</span> là sai số của hàm phân loại <span class="math inline">\(b(\textbf{x}_i,\theta_m)\)</span>
<span class="math display">\[\begin{align}
err_m = \cfrac{\sum\limits_{i=1}^n w_i^{(m)}  \cdot  \mathbb{I}(y_i \neq b(\textbf{x}_i,\theta_m))}{\sum\limits_{i=1}^n w_i^{(m)}}
\end{align}\]</span></p>
<p>Chúng ta cập nhật trọng số cho bước tiếp theo như sau
<span class="math display">\[\begin{align}
w_i^{(m+1)}&amp; = \exp\left[- y_i \cdot f_m(x_i)\right] \\
&amp; = exp\left[- y_i \cdot f_{m-1}(x_i) - y_i \lambda_m b(x_i,\theta_m) \right] \\
&amp; = w_i^{(m)} \cdot \exp\left[ \lambda_m \cdot(2 \mathbb{I}(b(x_i,\theta_m) \neq y_i) - 1)  \right] \\
&amp; = w_i^{(m)} \cdot \exp\left[ (2\lambda_m) \cdot \mathbb{I}(b(x_i,\theta_m) \neq y_i)  \right] \cdot \exp(-\lambda_m)
\end{align}\]</span>
Công thức ở trên tương đương với bước 2.(d) trong thuật toán AdaBoost.M1 với <span class="math inline">\((2\lambda_m) = \alpha_m\)</span>. Giá trị <span class="math inline">\(\exp(-\lambda_m)\)</span> không ảnh hưởng đến trọng số vì không phụ thuộc vào <span class="math inline">\(i\)</span>.</p>
<ul>
<li>Ví dụ 1: chúng ta sẽ áp dụng thuật toán AdaBoost.M1 trên một dữ liệu có 10 quan sát như dưới đây. Dữ liệu có biến mục tiêu <span class="math inline">\(Y\)</span> nhận giá trị 1 khi khách hàng đồng ý mua sản phẩm và nhận giá trị -1 khi khách hành không đồng ý. Có bốn biến giải thích là độ tuổi (<span class="math inline">\(Age\)</span>), số năm kinh nghiệm lái xe (<span class="math inline">\(seniority\)</span>), giới tính (<span class="math inline">\(sex\)</span>) và thành thị (<span class="math inline">\(urban\)</span>). Hàm phân loại chúng ta lựa chọn là cây quyết định có 1 node duy nhất.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="boosting-và-cây-quyết-định..html#cb10-1" tabindex="-1"></a>df<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;C:/Users/AD/Desktop/Tex file/Thu latex/Book demo/bookdown_demo_hieu/AdaBoostM1Example1.csv&quot;</span>)</span>
<span id="cb10-2"><a href="boosting-và-cây-quyết-định..html#cb10-2" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(df, <span class="at">booktabs =</span> T,</span>
<span id="cb10-3"><a href="boosting-và-cây-quyết-định..html#cb10-3" tabindex="-1"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&quot;Tuổi&quot;</span>, <span class="st">&quot;Kinh nghiệm&quot;</span>, <span class="st">&quot;Giới tính&quot;</span>, <span class="st">&quot;Thành thị&quot;</span>, <span class="st">&quot;Lựa chọn&quot;</span>),</span>
<span id="cb10-4"><a href="boosting-và-cây-quyết-định..html#cb10-4" tabindex="-1"></a>      <span class="at">escape=</span>F, <span class="at">align =</span> <span class="st">&#39;r&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="boosting-và-cây-quyết-định..html#cb10-5" tabindex="-1"></a>  <span class="co">#column_spec(c(1,4,5,6,7),border_left = T) %&gt;% column_spec(7,border_right = T) %&gt;% </span></span>
<span id="cb10-6"><a href="boosting-và-cây-quyết-định..html#cb10-6" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">latex_options =</span> <span class="st">&quot;scale_down&quot;</span>,<span class="at">full_width =</span> F)</span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Tuổi
</th>
<th style="text-align:right;">
Kinh nghiệm
</th>
<th style="text-align:right;">
Giới tính
</th>
<th style="text-align:right;">
Thành thị
</th>
<th style="text-align:right;">
Lựa chọn
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
</tr>
<tr>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
59
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
64
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1
</td>
</tr>
<tr>
<td style="text-align:right;">
59
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1
</td>
</tr>
<tr>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
</tr>
<tr>
<td style="text-align:right;">
43
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
</tr>
</tbody>
</table>
<p>Tại bước <span class="math inline">\(m=1\)</span> chúng ta có tỷ trọng của mỗi hàng dữ liệu là <span class="math inline">\(w^{(1)}_i = 0.1\)</span>; để xây dựng mô hình cây quyết định với 1 node và tôi thiểu hóa sai số trên dữ liệu, chúng ta thử trên từng cột dữ liệu</p>
<ul>
<li><p>Cột <span class="math inline">\(age\)</span>, bạn đọc có thể kiểm tra rằng tại điểm cắt 55.5 (tuổi), cây quyết định cho sai số có trọng số <span class="math inline">\(w^{(1)}_i\)</span> nhỏ nhất là 0.3. Lưu ý rằng điểm cắt 48 tuổi cũng có sai số là 0.3 tuy nhiên điểm cắt này chia dữ liệu thành một phần chỉ có 2 quan sát và một phần có 8 quan sát nên ít tối ưu hơn so với điểm cắt 55.5.</p></li>
<li><p>Cột <span class="math inline">\(seniority\)</span>, điểm cắt tối ưu là 24.5 (năm) và cũng cho sai số có trọng số là 0.3</p></li>
<li><p>Cột <span class="math inline">\(sex\)</span> chỉ có một lựa chọn là chia dữ liệu thành hai phần, Male và Female, cho sai số có trọng số là 0.3</p></li>
<li><p>Cột <span class="math inline">\(urban\)</span> chỉ có một lựa chọn là chia dữ liệu thành 0 và 1, cũng cho sai số có trọng số là 0.3</p></li>
</ul>
<p>Chúng ta chọn cây quyết định dựa trên biến <span class="math inline">\(age\)</span> với điểm cắt là 55.5 tuổi là hàm phân loại tại <span class="math inline">\(m = 1\)</span>. Cây quyết định cho giá trị là 1 khi biến <span class="math inline">\(age\)</span> nhỏ hơn 55.5 và cho giá trị là -1 khi biến <span class="math inline">\(age\)</span> cho giá trị lớn hơn 1. Hệ số của hàm phân loại thứ nhất trong hàm phân loại tổng là
<span class="math display">\[\begin{align}
alpha_1 = log(\cfrac{1 - err_1}{err_1}) = log(\cfrac{1-0.3}{0.3}) = 0.8473
\end{align}\]</span></p>
<p>Trọng số cho bước thứ 2 được cập nhật, theo công thức 2.(d) như sau
<span class="math display">\[\begin{align}
w^{(2)}_i = w^{(1)}_i \cdot \exp\left[ 0.8473 \cdot \mathbb{I} \left(f_m^C(\textbf{x}_i) \neq y_i \right) \right] =
  \begin{cases}
  0.1 \cdot e^0 \textit{ nếu }  f_m^C(\textbf{x}_i) = y_i \\
  0.1 \cdot e^{0.8473} \textit{ nếu }  f_m^C(\textbf{x}_i) \neq y_i
  \end{cases}
\end{align}\]</span></p>
<p>Bạn đọc có thể thấy rằng trọng số cho 3 hàng bị dự đoán sai đã được tăng lên thành <span class="math inline">\(0.1 \times e^{0.8473}\)</span> trong khi trọng số cho 7 hàng được dự đoán đúng vẫn là 0.1. Chuẩn hóa lại trọng số để có tổng bằng 1 chúng ta có bảng sau</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="boosting-và-cây-quyết-định..html#cb11-1" tabindex="-1"></a>df<span class="ot">&lt;-</span><span class="fu">mutate</span>(df, <span class="at">w1 =</span> <span class="fl">0.1</span>, <span class="at">pred1 =</span> <span class="fu">ifelse</span>(age<span class="sc">&lt;</span><span class="dv">48</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb11-2"><a href="boosting-và-cây-quyết-định..html#cb11-2" tabindex="-1"></a>df<span class="ot">&lt;-</span><span class="fu">mutate</span>(df, <span class="at">w2 =</span> <span class="fu">ifelse</span>(Y <span class="sc">==</span> pred1, <span class="fl">0.1</span>,<span class="fu">exp</span>(<span class="fl">0.8573</span>)))</span>
<span id="cb11-3"><a href="boosting-và-cây-quyết-định..html#cb11-3" tabindex="-1"></a>df<span class="ot">&lt;-</span><span class="fu">mutate</span>(df, <span class="at">w2 =</span> <span class="fu">round</span>(w2<span class="sc">/</span><span class="fu">sum</span>(w2),<span class="dv">3</span>))</span>
<span id="cb11-4"><a href="boosting-và-cây-quyết-định..html#cb11-4" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(df, <span class="at">booktabs =</span> T,</span>
<span id="cb11-5"><a href="boosting-và-cây-quyết-định..html#cb11-5" tabindex="-1"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&quot;Tuổi&quot;</span>, <span class="st">&quot;Kinh nghiệm&quot;</span>, <span class="st">&quot;Giới tính&quot;</span>, <span class="st">&quot;Thành thị&quot;</span>, <span class="st">&quot;Y&quot;</span>, <span class="st">&quot;$w^{(1)}$&quot;</span>, <span class="st">&quot;$b(x_i,</span><span class="sc">\\</span><span class="st">theta_1)$&quot;</span>, <span class="st">&quot;$w^{(2)}$&quot;</span> ),</span>
<span id="cb11-6"><a href="boosting-và-cây-quyết-định..html#cb11-6" tabindex="-1"></a>      <span class="at">escape=</span>F, <span class="at">align =</span> <span class="st">&#39;r&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-7"><a href="boosting-và-cây-quyết-định..html#cb11-7" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">latex_options =</span> <span class="st">&quot;scale_down&quot;</span>,<span class="at">full_width =</span> F)</span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Tuổi
</th>
<th style="text-align:right;">
Kinh nghiệm
</th>
<th style="text-align:right;">
Giới tính
</th>
<th style="text-align:right;">
Thành thị
</th>
<th style="text-align:right;">
Y
</th>
<th style="text-align:right;">
<span class="math inline">\(w^{(1)}\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(b(x_i,\theta_1)\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(w^{(2)}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.303
</td>
</tr>
<tr>
<td style="text-align:right;">
59
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.303
</td>
</tr>
<tr>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.303
</td>
</tr>
<tr>
<td style="text-align:right;">
64
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
59
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
F
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
43
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
M
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
</tbody>
</table>
<p>Tại bước <span class="math inline">\(m=2\)</span>, chúng ta cần tìm cây quyết định để tối thiểu hóa sai số có trọng số <span class="math inline">\(w^{(2)}\)</span> như bảng ở trên.</p>
<ul>
<li><p>Cột <span class="math inline">\(age\)</span>, bạn đọc có thể kiểm tra rằng tại điểm cắt 64.5 (tuổi), cây quyết định cho sai số có trọng số <span class="math inline">\(w^{(2)}_i\)</span> nhỏ nhất là 0.342</p></li>
<li><p>Cột <span class="math inline">\(seniority\)</span>, điểm cắt tối ưu là 24.5 (năm) cho sai số có trọng số là 0.329</p></li>
<li><p>Cột <span class="math inline">\(sex\)</span> chỉ có một lựa chọn là chia dữ liệu thành hai phần, Male và Female, cho sai số có trọng số là 0.329</p></li>
<li><p>Cột <span class="math inline">\(urban\)</span> chỉ có một lựa chọn là chia dữ liệu thành 0 và 1, cũng cho sai số có trọng số là 0.039</p></li>
</ul>
<p>Như vậy, cây quyết định dựa trên biến <span class="math inline">\(urban\)</span> sẽ là cây quyết định tại bước thứ hai. Cây quyết định trả lại giá trị là <span class="math inline">\(1\)</span> khi <span class="math inline">\(urban = 1\)</span> và trả lại giá trị <span class="math inline">\(-1\)</span> khi <span class="math inline">\(urban = 0\)</span> Hệ số của hàm phân loại thứ hai trong hàm phân loại tổng là
<span class="math display">\[\begin{align}
alpha_2 = log(\cfrac{1-0.039}{0.039}) = 3.204
\end{align}\]</span></p>
<p>Với <span class="math inline">\(M = 2\)</span> chúng ta có hàm phân loại từ thuật toán AdaBoost.M1 được xây dựng dựa trên dữ liệu cho bởi bảng … như sau
<span class="math display">\[\begin{align}
f^C = sign(0.8473 \cdot f^C_1 + 3.204 \cdot f^C_2) = \begin{cases}
-1 \textit{ nếu } age &lt; 55.5 \textit{ và } urban = 0 \\
-1 \textit{ nếu } age &gt; 55.5 \textit{ và } urban = 0 \\
-1 \textit{ nếu } age &lt; 55.5 \textit{ và } urban = 1 \\
1 \textit{ nếu } age &gt; 55.5 \textit{ và } urban = 1
\end{cases}

\end{align}\]</span></p>
<p>Mặc dù chúng tôi sử dụng hàm tổn thất kiểu mũ để giải thích các bước của AdaBoost.M1, tuy nhiên thực tế thì thuật toán AdaBoost.M1 lại được xây dựng dựa trên khía cạnh khác</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="reference.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
